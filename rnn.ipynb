{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901b4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from dataset import ptb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5923d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnnlm:\n",
    "    \n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        \n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed = (rn(V, D) / 100).astype('f')\n",
    "        rnnWx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnnWh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnnb = np.zeros(H).astype('f')\n",
    "        affineW = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affineb = np.zeros(V).astype('f')\n",
    "        \n",
    "        self.params = [embed, rnnWx, rnnWh, rnnb, affineW, affineb]\n",
    "        self.grads = []\n",
    "        self.rnn = []\n",
    "        \n",
    "        self.wordvec_size = wordvec_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.time_idx = 0\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        embed, rnnWx, rnnWh, rnnb, affineW, affineb = self.params\n",
    "                \n",
    "        batch_size, time_size = x.shape\n",
    "        wordvec_size = self.wordvec_size\n",
    "        hidden_size = self.hidden_size\n",
    "        \n",
    "        self.rnn = []\n",
    "        \n",
    "        h_prev = np.zeros((batch_size, hidden_size), dtype='f')\n",
    "        hs = np.empty((batch_size, time_size, hidden_size), dtype='f')\n",
    "        for t in range(time_size):\n",
    "            # embed\n",
    "            emb_out = embed[x[:, t]]\n",
    "            \n",
    "            #rnn\n",
    "            h_next = np.matmul(h_prev, rnnWh) + np.matmul(emb_out, rnnWx) + rnnb\n",
    "            h_next = np.tanh(h_next)\n",
    "            \n",
    "            self.rnn.append([emb_out, h_prev, h_next])\n",
    "            h_prev = h_next\n",
    "            hs[:, t, :] = h_prev\n",
    "        \n",
    "        # affine\n",
    "        affine_out = np.matmul(hs, affineW) + affineb\n",
    "        \n",
    "        # softmax\n",
    "        y = self.softmax(affine_out)\n",
    "        \n",
    "        loss = self.getLoss(y, batch_t)\n",
    "        self.xs = x, hs, affine_out, y\n",
    "\n",
    "        return y, loss\n",
    "    \n",
    "    def backward(self, t):\n",
    "        embed, rnnWx, rnnWh, rnnb, affineW, affineb = self.params\n",
    "        x, hs, affine_out, y = self.xs\n",
    "        \n",
    "        wordvec_size = self.wordvec_size\n",
    "        vocab_size = self.vocab_size\n",
    "        batch_size, time_size = x.shape\n",
    "        \n",
    "        # softmax\n",
    "        y = y.reshape(batch_size * time_size, -1)\n",
    "        t = t.reshape(batch_size * time_size)\n",
    "        y[np.arange(batch_size * time_size), t] -= 1\n",
    "        soft_dout = y\n",
    "        \n",
    "        # affine\n",
    "        affine_dout = np.matmul(soft_dout, affineW.T).reshape(batch_size, time_size, -1) # (b, t, h)\n",
    "        affinedW = np.matmul(hs.reshape(batch_size * time_size, -1).T, soft_dout) # (h, v)\n",
    "        affinedb = np.sum(soft_dout, axis=0)\n",
    "        \n",
    "        # rnn\n",
    "        rnndWx = np.zeros_like(rnnWx)\n",
    "        rnndWh = np.zeros_like(rnnWh)\n",
    "        rnndb = np.zeros_like(rnnb)\n",
    "        \n",
    "        rnn_douts = np.empty((batch_size, time_size, wordvec_size), dtype='f')\n",
    "        dh = 0\n",
    "        for t in reversed(range(time_size)):\n",
    "            emb_out, h_prev, h_next = self.rnn[t]\n",
    "            \n",
    "            dh_next = affine_dout[:, t, :] + dh\n",
    "            tanh_dout = dh_next * (1 - h_next ** 2)\n",
    "            \n",
    "            dWx = np.matmul(emb_out.T, tanh_dout)\n",
    "            rnn_dout = np.matmul(tanh_dout, rnnWx.T)\n",
    "            rnn_douts[:, t, :] = rnn_dout\n",
    "            \n",
    "            dWh = np.matmul(h_prev.T, tanh_dout)\n",
    "            dh_prev = np.matmul(tanh_dout, rnnWh.T)\n",
    "            \n",
    "            db = np.sum(tanh_dout, axis=0)\n",
    "            \n",
    "            rnndWx += dWx\n",
    "            rnndWh += dWh\n",
    "            rnndb += db\n",
    "            \n",
    "            dh = dh_prev\n",
    "        \n",
    "        # embed\n",
    "        embed_dout = np.zeros_like(embed)\n",
    "        for t in range(time_size):\n",
    "            np.add.at(embed_dout, x[:, t], rnn_douts[:, t, :])\n",
    "        \n",
    "        self.grads = embed_dout, rnndWx, rnndWh, rnndb, affinedW, affinedb\n",
    "        \n",
    "        \n",
    "    def softmax(self, y):\n",
    "        y = y - np.max(y)\n",
    "        y = np.exp(y)\n",
    "        y = y / y.sum(axis=2, keepdims=True)\n",
    "        return y\n",
    "    \n",
    "    def update(self, lr):\n",
    "        for i in range(len(self.params)):\n",
    "            self.params[i] -= self.grads[i] * lr      \n",
    "            \n",
    "    def getLoss(self, y, t):\n",
    "        N, T, V = y.shape\n",
    "\n",
    "        y = y.reshape(N * T, V)\n",
    "        t = t.reshape(N * T)\n",
    "\n",
    "        ls = np.log(y[np.arange(N * T), t])\n",
    "        return -np.sum(ls) / (N * T)\n",
    "    \n",
    "    def get_batch(self, x, t, batch_size, time_size):\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "\n",
    "        data_size = len(x)\n",
    "        jump = data_size // batch_size\n",
    "        offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "        for time in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, time] = x[(offset + self.time_idx) % data_size]\n",
    "                batch_t[i, time] = t[(offset + self.time_idx) % data_size]\n",
    "            self.time_idx += 1\n",
    "        return batch_x, batch_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52e1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000  \n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "xs = corpus[:-1] \n",
    "ts = corpus[1:]  \n",
    "\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  \n",
    "time_size = 5  \n",
    "lr = 0.01\n",
    "max_epoch = 100\n",
    "max_iters = len(xs) // (batch_size * time_size)\n",
    "eval_interval = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b15a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2cd95d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | time 0[s] | loss 6.04 | ppl 417.96\n",
      "| epoch 2 | time 0[s] | loss 5.28 | ppl 316.73\n",
      "| epoch 3 | time 0[s] | loss 5.58 | ppl 237.14\n",
      "| epoch 4 | time 0[s] | loss 5.60 | ppl 213.93\n",
      "| epoch 5 | time 0[s] | loss 5.11 | ppl 200.11\n",
      "| epoch 6 | time 0[s] | loss 5.36 | ppl 191.45\n",
      "| epoch 7 | time 0[s] | loss 5.14 | ppl 177.05\n",
      "| epoch 8 | time 0[s] | loss 5.34 | ppl 168.65\n",
      "| epoch 9 | time 0[s] | loss 5.07 | ppl 152.95\n",
      "| epoch 10 | time 1[s] | loss 4.92 | ppl 137.70\n",
      "| epoch 11 | time 1[s] | loss 4.87 | ppl 125.14\n",
      "| epoch 12 | time 1[s] | loss 4.74 | ppl 112.91\n",
      "| epoch 13 | time 1[s] | loss 4.58 | ppl 104.32\n",
      "| epoch 14 | time 1[s] | loss 4.40 | ppl 88.55\n",
      "| epoch 15 | time 1[s] | loss 3.84 | ppl 75.84\n",
      "| epoch 16 | time 1[s] | loss 4.07 | ppl 67.05\n",
      "| epoch 17 | time 1[s] | loss 4.16 | ppl 58.21\n",
      "| epoch 18 | time 1[s] | loss 4.12 | ppl 50.83\n",
      "| epoch 19 | time 1[s] | loss 4.12 | ppl 40.33\n",
      "| epoch 20 | time 2[s] | loss 3.69 | ppl 34.53\n",
      "| epoch 21 | time 2[s] | loss 3.51 | ppl 30.85\n",
      "| epoch 22 | time 2[s] | loss 3.00 | ppl 26.45\n",
      "| epoch 23 | time 2[s] | loss 2.83 | ppl 23.62\n",
      "| epoch 24 | time 2[s] | loss 2.79 | ppl 20.25\n",
      "| epoch 25 | time 2[s] | loss 2.58 | ppl 18.02\n",
      "| epoch 26 | time 2[s] | loss 2.58 | ppl 15.89\n",
      "| epoch 27 | time 2[s] | loss 2.34 | ppl 13.90\n",
      "| epoch 28 | time 3[s] | loss 2.49 | ppl 12.67\n",
      "| epoch 29 | time 3[s] | loss 2.32 | ppl 11.14\n",
      "| epoch 30 | time 3[s] | loss 2.08 | ppl 9.53\n",
      "| epoch 31 | time 3[s] | loss 2.29 | ppl 8.82\n",
      "| epoch 32 | time 3[s] | loss 1.93 | ppl 7.90\n",
      "| epoch 33 | time 3[s] | loss 2.04 | ppl 7.34\n",
      "| epoch 34 | time 3[s] | loss 1.84 | ppl 6.65\n",
      "| epoch 35 | time 3[s] | loss 1.88 | ppl 6.14\n",
      "| epoch 36 | time 3[s] | loss 1.37 | ppl 5.44\n",
      "| epoch 37 | time 4[s] | loss 1.58 | ppl 5.17\n",
      "| epoch 38 | time 4[s] | loss 1.68 | ppl 4.91\n",
      "| epoch 39 | time 4[s] | loss 1.33 | ppl 4.46\n",
      "| epoch 40 | time 4[s] | loss 1.36 | ppl 4.14\n",
      "| epoch 41 | time 4[s] | loss 1.47 | ppl 4.03\n",
      "| epoch 42 | time 4[s] | loss 1.34 | ppl 3.74\n",
      "| epoch 43 | time 4[s] | loss 1.25 | ppl 3.45\n",
      "| epoch 44 | time 5[s] | loss 1.08 | ppl 3.43\n",
      "| epoch 45 | time 5[s] | loss 1.27 | ppl 3.36\n",
      "| epoch 46 | time 5[s] | loss 1.13 | ppl 3.01\n",
      "| epoch 47 | time 5[s] | loss 1.11 | ppl 2.91\n",
      "| epoch 48 | time 5[s] | loss 1.07 | ppl 2.86\n",
      "| epoch 49 | time 5[s] | loss 1.18 | ppl 2.76\n",
      "| epoch 50 | time 5[s] | loss 1.11 | ppl 2.72\n",
      "| epoch 51 | time 5[s] | loss 0.89 | ppl 2.53\n",
      "| epoch 52 | time 6[s] | loss 0.94 | ppl 2.50\n",
      "| epoch 53 | time 6[s] | loss 0.84 | ppl 2.45\n",
      "| epoch 54 | time 6[s] | loss 0.83 | ppl 2.48\n",
      "| epoch 55 | time 6[s] | loss 0.77 | ppl 2.37\n",
      "| epoch 56 | time 6[s] | loss 0.75 | ppl 2.31\n",
      "| epoch 57 | time 6[s] | loss 0.92 | ppl 2.23\n",
      "| epoch 58 | time 6[s] | loss 0.78 | ppl 2.17\n",
      "| epoch 59 | time 6[s] | loss 0.87 | ppl 2.23\n",
      "| epoch 60 | time 6[s] | loss 0.95 | ppl 2.29\n",
      "| epoch 61 | time 7[s] | loss 0.61 | ppl 2.04\n",
      "| epoch 62 | time 7[s] | loss 0.67 | ppl 2.02\n",
      "| epoch 63 | time 7[s] | loss 0.74 | ppl 2.10\n",
      "| epoch 64 | time 7[s] | loss 0.88 | ppl 2.11\n",
      "| epoch 65 | time 7[s] | loss 0.63 | ppl 2.04\n",
      "| epoch 66 | time 7[s] | loss 0.66 | ppl 1.91\n",
      "| epoch 67 | time 7[s] | loss 0.81 | ppl 1.95\n",
      "| epoch 68 | time 7[s] | loss 0.47 | ppl 1.98\n",
      "| epoch 69 | time 7[s] | loss 0.78 | ppl 2.05\n",
      "| epoch 70 | time 7[s] | loss 0.56 | ppl 1.90\n",
      "| epoch 71 | time 8[s] | loss 0.54 | ppl 1.83\n",
      "| epoch 72 | time 8[s] | loss 0.57 | ppl 1.89\n",
      "| epoch 73 | time 8[s] | loss 0.80 | ppl 1.93\n",
      "| epoch 74 | time 8[s] | loss 0.66 | ppl 1.90\n",
      "| epoch 75 | time 8[s] | loss 0.78 | ppl 1.90\n",
      "| epoch 76 | time 8[s] | loss 0.63 | ppl 1.81\n",
      "| epoch 77 | time 8[s] | loss 0.64 | ppl 1.78\n",
      "| epoch 78 | time 8[s] | loss 0.72 | ppl 1.90\n",
      "| epoch 79 | time 8[s] | loss 0.65 | ppl 1.85\n",
      "| epoch 80 | time 9[s] | loss 0.65 | ppl 1.78\n",
      "| epoch 81 | time 9[s] | loss 0.74 | ppl 1.75\n",
      "| epoch 82 | time 9[s] | loss 0.69 | ppl 1.84\n",
      "| epoch 83 | time 9[s] | loss 0.49 | ppl 1.79\n",
      "| epoch 84 | time 9[s] | loss 0.39 | ppl 1.80\n",
      "| epoch 85 | time 9[s] | loss 0.49 | ppl 1.73\n",
      "| epoch 86 | time 9[s] | loss 0.43 | ppl 1.71\n",
      "| epoch 87 | time 9[s] | loss 0.66 | ppl 1.81\n",
      "| epoch 88 | time 10[s] | loss 0.69 | ppl 1.80\n",
      "| epoch 89 | time 10[s] | loss 0.42 | ppl 1.73\n",
      "| epoch 90 | time 10[s] | loss 0.46 | ppl 1.72\n",
      "| epoch 91 | time 10[s] | loss 0.58 | ppl 1.78\n",
      "| epoch 92 | time 10[s] | loss 0.56 | ppl 1.73\n",
      "| epoch 93 | time 10[s] | loss 0.65 | ppl 1.79\n",
      "| epoch 94 | time 10[s] | loss 0.63 | ppl 1.77\n",
      "| epoch 95 | time 10[s] | loss 0.26 | ppl 1.66\n",
      "| epoch 96 | time 10[s] | loss 0.74 | ppl 1.72\n",
      "| epoch 97 | time 11[s] | loss 0.57 | ppl 1.72\n",
      "| epoch 98 | time 11[s] | loss 0.43 | ppl 1.78\n",
      "| epoch 99 | time 11[s] | loss 0.55 | ppl 1.72\n",
      "| epoch 100 | time 11[s] | loss 0.48 | ppl 1.65\n"
     ]
    }
   ],
   "source": [
    "ppl_list = []\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "start_time = time.time()\n",
    "model.time_idx = 0\n",
    "for epoch in range(max_epoch):\n",
    "    for iters in range(max_iters):\n",
    "        batch_x, batch_t = model.get_batch(xs, ts, batch_size, time_size)\n",
    "\n",
    "        y, loss = model.forward(batch_x, batch_t)\n",
    "        model.backward(batch_t)\n",
    "        model.update(lr)\n",
    "        \n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "        if ((iters % eval_interval) == 0):\n",
    "            ppl = np.exp(total_loss / loss_count)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('| epoch %d | time %d[s] | loss %.2f | ppl %.2f'\n",
    "                % (epoch + 1, elapsed_time, loss, ppl))\n",
    "            ppl_list.append(float(ppl))\n",
    "            total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e10200c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('iters (x' + str(eval_interval) + ')')\n",
    "plt.ylabel('ppl')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
