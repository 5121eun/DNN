{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "901b4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from dataset import ptb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5923d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnnlm:\n",
    "    \n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        \n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed = (rn(V, D) / 100).astype('f')\n",
    "        rnnWx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnnWh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnnb = np.zeros(H).astype('f')\n",
    "        affineW = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affineb = np.zeros(V).astype('f')\n",
    "        \n",
    "        self.params = [embed, rnnWx, rnnWh, rnnb, affineW, affineb]\n",
    "        self.grads = []\n",
    "        self.rnn = []\n",
    "        \n",
    "        self.wordvec_size = wordvec_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.time_idx = 0\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        embed, rnnWx, rnnWh, rnnb, affineW, affineb = self.params\n",
    "        \n",
    "        batch_size, time_size = x.shape\n",
    "        wordvec_size = self.wordvec_size\n",
    "        hidden_size = self.hidden_size\n",
    "        \n",
    "        h_prev = np.zeros((batch_size, hidden_size), dtype='f')\n",
    "        hs = np.empty((batch_size, time_size, hidden_size), dtype='f')\n",
    "        for t in range(time_size):\n",
    "            # embed\n",
    "            emb_out = embed[x[:, t]]\n",
    "            \n",
    "            #rnn\n",
    "            h_next = np.matmul(h_prev, rnnWh) + np.matmul(emb_out, rnnWx) + rnnb\n",
    "            h_next = np.tanh(h_next)\n",
    "            \n",
    "            self.rnn.append([emb_out, h_prev, h_next])\n",
    "            h_prev = h_next\n",
    "            hs[:, t, :] = h_prev\n",
    "        \n",
    "        # affine\n",
    "        affine_out = np.matmul(hs, affineW) + affineb\n",
    "        \n",
    "        # softmax\n",
    "        y = self.softmax(affine_out)\n",
    "        \n",
    "        loss = self.getLoss(y, batch_t)\n",
    "        self.xs = x, hs, affine_out, y\n",
    "\n",
    "        return y, loss\n",
    "    \n",
    "    def backward(self, t):\n",
    "        embed, rnnWx, rnnWh, rnnb, affineW, affineb = self.params\n",
    "        x, hs, affine_out, y = self.xs\n",
    "        \n",
    "        wordvec_size = self.wordvec_size\n",
    "        vocab_size = self.vocab_size\n",
    "        batch_size, time_size = x.shape\n",
    "        \n",
    "        # softmax\n",
    "        y = y.reshape(batch_size * time_size, -1)\n",
    "        t = t.reshape(batch_size * time_size)\n",
    "        y[np.arange(batch_size * time_size), t] -= 1\n",
    "        soft_dout = y\n",
    "        \n",
    "        # affine\n",
    "        affine_dout = np.matmul(soft_dout, affineW.T).reshape(batch_size, time_size, -1) # (b, t, h)\n",
    "        affinedW = np.matmul(hs.reshape(batch_size * time_size, -1).T, soft_dout) # (h, v)\n",
    "        affinedb = np.sum(soft_dout, axis=0)\n",
    "        \n",
    "        # rnn\n",
    "        rnndWx = np.zeros_like(rnnWx)\n",
    "        rnndWh = np.zeros_like(rnnWh)\n",
    "        rnndb = np.zeros_like(rnnb)\n",
    "        \n",
    "        rnn_douts = np.empty((batch_size, time_size, wordvec_size), dtype='f')\n",
    "        dh = 0\n",
    "        for t in reversed(range(time_size)):\n",
    "            emb_out, h_prev, h_next = self.rnn[t]\n",
    "            \n",
    "            dh_next = affine_dout[:, t, :] + dh\n",
    "            tanh_dout = dh_next * (1 - h_next ** 2)\n",
    "            \n",
    "            dWx = np.matmul(emb_out.T, tanh_dout)\n",
    "            rnn_dout = np.matmul(tanh_dout, rnnWx.T)\n",
    "            rnn_douts[:, t, :] = rnn_dout\n",
    "            \n",
    "            dWh = np.matmul(h_prev.T, tanh_dout)\n",
    "            dh_prev = np.matmul(tanh_dout, rnnWh.T)\n",
    "            \n",
    "            db = np.sum(tanh_dout, axis=0)\n",
    "            \n",
    "            rnndWx += dWx\n",
    "            rnndWh += dWh\n",
    "            rnndb += db\n",
    "            \n",
    "            dh = dh_prev\n",
    "        \n",
    "        # embed\n",
    "        embed_dout = np.zeros_like(embed)\n",
    "        for t in range(time_size):\n",
    "            np.add.at(embed_dout, x[:, t], rnn_douts[:, t, :])\n",
    "        \n",
    "        self.grads = embed_dout, rnndWx, rnndWh, rnndb, affinedW, affinedb\n",
    "        \n",
    "        \n",
    "    def softmax(self, y):\n",
    "        y = y - np.max(y)\n",
    "        y = np.exp(y)\n",
    "        y = y / y.sum(axis=2, keepdims=True)\n",
    "        return y\n",
    "    \n",
    "    def update(self, lr):\n",
    "        for i in range(len(self.params)):\n",
    "            self.params[i] -= self.grads[i] * lr      \n",
    "            \n",
    "    def getLoss(self, y, t):\n",
    "        N, T, V = y.shape\n",
    "\n",
    "        y = y.reshape(N * T, V)\n",
    "        t = t.reshape(N * T)\n",
    "\n",
    "        ls = np.log(y[np.arange(N * T), t])\n",
    "        return -np.sum(ls) / (N * T)\n",
    "    \n",
    "    def get_batch(self, x, t, batch_size, time_size):\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "\n",
    "        data_size = len(x)\n",
    "        jump = data_size // batch_size\n",
    "        offsets = [i * jump for i in range(batch_size)]  # 배치에서 각 샘플을 읽기 시작하는 위치\n",
    "\n",
    "        for time in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, time] = x[(offset + self.time_idx) % data_size]\n",
    "                batch_t[i, time] = t[(offset + self.time_idx) % data_size]\n",
    "            self.time_idx += 1\n",
    "        return batch_x, batch_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52e1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000  # 테스트 데이터셋을 작게 설정\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]  # 출력（정답 레이블）\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5  # RNN을 펼치는 크기\n",
    "lr = 0.01\n",
    "max_epoch = 100\n",
    "max_iters = len(xs) // (batch_size * time_size)\n",
    "eval_interval = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b15a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2cd95d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 | 시간 0[s] | loss 6.03 | 퍼플렉서티 417.35\n",
      "| 에폭 2 | 시간 0[s] | loss 5.16 | 퍼플렉서티 321.76\n",
      "| 에폭 3 | 시간 0[s] | loss 5.63 | 퍼플렉서티 227.37\n",
      "| 에폭 4 | 시간 0[s] | loss 5.52 | 퍼플렉서티 206.60\n",
      "| 에폭 5 | 시간 0[s] | loss 5.11 | 퍼플렉서티 197.71\n",
      "| 에폭 6 | 시간 0[s] | loss 5.34 | 퍼플렉서티 191.59\n",
      "| 에폭 7 | 시간 0[s] | loss 5.11 | 퍼플렉서티 174.86\n",
      "| 에폭 8 | 시간 0[s] | loss 5.34 | 퍼플렉서티 170.00\n",
      "| 에폭 9 | 시간 0[s] | loss 5.15 | 퍼플렉서티 160.34\n",
      "| 에폭 10 | 시간 0[s] | loss 5.03 | 퍼플렉서티 148.52\n",
      "| 에폭 11 | 시간 0[s] | loss 5.07 | 퍼플렉서티 142.75\n",
      "| 에폭 12 | 시간 0[s] | loss 5.05 | 퍼플렉서티 132.31\n",
      "| 에폭 13 | 시간 0[s] | loss 5.07 | 퍼플렉서티 127.37\n",
      "| 에폭 14 | 시간 0[s] | loss 4.68 | 퍼플렉서티 117.03\n",
      "| 에폭 15 | 시간 0[s] | loss 4.32 | 퍼플렉서티 107.12\n",
      "| 에폭 16 | 시간 0[s] | loss 4.43 | 퍼플렉서티 101.90\n",
      "| 에폭 17 | 시간 0[s] | loss 4.62 | 퍼플렉서티 93.18\n",
      "| 에폭 18 | 시간 0[s] | loss 4.77 | 퍼플렉서티 84.37\n",
      "| 에폭 19 | 시간 0[s] | loss 4.65 | 퍼플렉서티 75.51\n",
      "| 에폭 20 | 시간 0[s] | loss 4.40 | 퍼플렉서티 68.26\n",
      "| 에폭 21 | 시간 0[s] | loss 4.11 | 퍼플렉서티 64.04\n",
      "| 에폭 22 | 시간 0[s] | loss 3.61 | 퍼플렉서티 57.37\n",
      "| 에폭 23 | 시간 0[s] | loss 3.88 | 퍼플렉서티 54.14\n",
      "| 에폭 24 | 시간 0[s] | loss 4.11 | 퍼플렉서티 48.43\n",
      "| 에폭 25 | 시간 0[s] | loss 3.51 | 퍼플렉서티 42.53\n",
      "| 에폭 26 | 시간 0[s] | loss 3.50 | 퍼플렉서티 40.65\n",
      "| 에폭 27 | 시간 0[s] | loss 3.04 | 퍼플렉서티 36.29\n",
      "| 에폭 28 | 시간 0[s] | loss 3.54 | 퍼플렉서티 34.13\n",
      "| 에폭 29 | 시간 0[s] | loss 3.54 | 퍼플렉서티 30.29\n",
      "| 에폭 30 | 시간 0[s] | loss 3.39 | 퍼플렉서티 27.98\n",
      "| 에폭 31 | 시간 0[s] | loss 3.54 | 퍼플렉서티 25.67\n",
      "| 에폭 32 | 시간 0[s] | loss 3.03 | 퍼플렉서티 23.97\n",
      "| 에폭 33 | 시간 0[s] | loss 2.92 | 퍼플렉서티 22.49\n",
      "| 에폭 34 | 시간 0[s] | loss 2.93 | 퍼플렉서티 20.85\n",
      "| 에폭 35 | 시간 0[s] | loss 2.74 | 퍼플렉서티 19.35\n",
      "| 에폭 36 | 시간 0[s] | loss 2.55 | 퍼플렉서티 17.95\n",
      "| 에폭 37 | 시간 0[s] | loss 3.04 | 퍼플렉서티 17.41\n",
      "| 에폭 38 | 시간 0[s] | loss 2.92 | 퍼플렉서티 15.88\n",
      "| 에폭 39 | 시간 0[s] | loss 2.87 | 퍼플렉서티 14.62\n",
      "| 에폭 40 | 시간 0[s] | loss 2.87 | 퍼플렉서티 13.96\n",
      "| 에폭 41 | 시간 1[s] | loss 2.73 | 퍼플렉서티 12.97\n",
      "| 에폭 42 | 시간 1[s] | loss 2.62 | 퍼플렉서티 12.42\n",
      "| 에폭 43 | 시간 1[s] | loss 2.34 | 퍼플렉서티 11.53\n",
      "| 에폭 44 | 시간 1[s] | loss 2.43 | 퍼플렉서티 11.19\n",
      "| 에폭 45 | 시간 1[s] | loss 2.08 | 퍼플렉서티 10.51\n",
      "| 에폭 46 | 시간 1[s] | loss 2.23 | 퍼플렉서티 10.03\n",
      "| 에폭 47 | 시간 1[s] | loss 2.10 | 퍼플렉서티 9.59\n",
      "| 에폭 48 | 시간 1[s] | loss 2.11 | 퍼플렉서티 9.18\n",
      "| 에폭 49 | 시간 1[s] | loss 2.16 | 퍼플렉서티 8.64\n",
      "| 에폭 50 | 시간 1[s] | loss 2.15 | 퍼플렉서티 8.20\n",
      "| 에폭 51 | 시간 1[s] | loss 2.05 | 퍼플렉서티 7.67\n",
      "| 에폭 52 | 시간 1[s] | loss 1.82 | 퍼플렉서티 7.59\n",
      "| 에폭 53 | 시간 1[s] | loss 1.89 | 퍼플렉서티 7.32\n",
      "| 에폭 54 | 시간 1[s] | loss 1.74 | 퍼플렉서티 6.91\n",
      "| 에폭 55 | 시간 1[s] | loss 1.62 | 퍼플렉서티 6.55\n",
      "| 에폭 56 | 시간 1[s] | loss 1.67 | 퍼플렉서티 6.55\n",
      "| 에폭 57 | 시간 1[s] | loss 2.02 | 퍼플렉서티 6.35\n",
      "| 에폭 58 | 시간 1[s] | loss 1.93 | 퍼플렉서티 5.81\n",
      "| 에폭 59 | 시간 1[s] | loss 1.92 | 퍼플렉서티 5.71\n",
      "| 에폭 60 | 시간 1[s] | loss 1.97 | 퍼플렉서티 5.59\n",
      "| 에폭 61 | 시간 1[s] | loss 1.76 | 퍼플렉서티 5.25\n",
      "| 에폭 62 | 시간 1[s] | loss 1.71 | 퍼플렉서티 5.17\n",
      "| 에폭 63 | 시간 1[s] | loss 1.51 | 퍼플렉서티 4.98\n",
      "| 에폭 64 | 시간 1[s] | loss 1.72 | 퍼플렉서티 5.01\n",
      "| 에폭 65 | 시간 1[s] | loss 1.42 | 퍼플렉서티 4.76\n",
      "| 에폭 66 | 시간 1[s] | loss 1.66 | 퍼플렉서티 4.63\n",
      "| 에폭 67 | 시간 1[s] | loss 1.51 | 퍼플렉서티 4.44\n",
      "| 에폭 68 | 시간 1[s] | loss 1.20 | 퍼플렉서티 4.38\n",
      "| 에폭 69 | 시간 1[s] | loss 1.31 | 퍼플렉서티 4.37\n",
      "| 에폭 70 | 시간 1[s] | loss 1.35 | 퍼플렉서티 4.06\n",
      "| 에폭 71 | 시간 1[s] | loss 1.45 | 퍼플렉서티 3.98\n",
      "| 에폭 72 | 시간 1[s] | loss 1.24 | 퍼플렉서티 4.00\n",
      "| 에폭 73 | 시간 1[s] | loss 1.52 | 퍼플렉서티 3.96\n",
      "| 에폭 74 | 시간 1[s] | loss 1.40 | 퍼플렉서티 3.70\n",
      "| 에폭 75 | 시간 1[s] | loss 1.35 | 퍼플렉서티 3.67\n",
      "| 에폭 76 | 시간 2[s] | loss 1.22 | 퍼플렉서티 3.68\n",
      "| 에폭 77 | 시간 2[s] | loss 1.32 | 퍼플렉서티 3.54\n",
      "| 에폭 78 | 시간 2[s] | loss 1.53 | 퍼플렉서티 3.57\n",
      "| 에폭 79 | 시간 2[s] | loss 1.28 | 퍼플렉서티 3.41\n",
      "| 에폭 80 | 시간 2[s] | loss 1.26 | 퍼플렉서티 3.35\n",
      "| 에폭 81 | 시간 2[s] | loss 1.27 | 퍼플렉서티 3.32\n",
      "| 에폭 82 | 시간 2[s] | loss 1.33 | 퍼플렉서티 3.26\n",
      "| 에폭 83 | 시간 2[s] | loss 1.04 | 퍼플렉서티 3.25\n",
      "| 에폭 84 | 시간 2[s] | loss 1.10 | 퍼플렉서티 3.18\n",
      "| 에폭 85 | 시간 2[s] | loss 1.03 | 퍼플렉서티 3.14\n",
      "| 에폭 86 | 시간 2[s] | loss 1.01 | 퍼플렉서티 3.04\n",
      "| 에폭 87 | 시간 2[s] | loss 1.15 | 퍼플렉서티 3.12\n",
      "| 에폭 88 | 시간 2[s] | loss 1.07 | 퍼플렉서티 3.07\n",
      "| 에폭 89 | 시간 2[s] | loss 0.98 | 퍼플렉서티 2.97\n",
      "| 에폭 90 | 시간 2[s] | loss 0.97 | 퍼플렉서티 2.95\n",
      "| 에폭 91 | 시간 2[s] | loss 1.07 | 퍼플렉서티 3.03\n",
      "| 에폭 92 | 시간 2[s] | loss 1.16 | 퍼플렉서티 2.94\n",
      "| 에폭 93 | 시간 2[s] | loss 1.19 | 퍼플렉서티 2.88\n",
      "| 에폭 94 | 시간 2[s] | loss 1.15 | 퍼플렉서티 2.82\n",
      "| 에폭 95 | 시간 2[s] | loss 0.84 | 퍼플렉서티 2.76\n",
      "| 에폭 96 | 시간 2[s] | loss 1.26 | 퍼플렉서티 2.82\n",
      "| 에폭 97 | 시간 2[s] | loss 1.07 | 퍼플렉서티 2.77\n",
      "| 에폭 98 | 시간 2[s] | loss 1.02 | 퍼플렉서티 2.70\n",
      "| 에폭 99 | 시간 2[s] | loss 1.02 | 퍼플렉서티 2.75\n",
      "| 에폭 100 | 시간 2[s] | loss 1.11 | 퍼플렉서티 2.71\n"
     ]
    }
   ],
   "source": [
    "ppl_list = []\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "start_time = time.time()\n",
    "model.time_idx = 0\n",
    "for epoch in range(max_epoch):\n",
    "    for iters in range(max_iters):\n",
    "        batch_x, batch_t = model.get_batch(xs, ts, batch_size, time_size)\n",
    "\n",
    "        y, loss = model.forward(batch_x, batch_t)\n",
    "        model.backward(batch_t)\n",
    "        model.update(lr)\n",
    "        \n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "        if ((iters % eval_interval) == 0):\n",
    "            ppl = np.exp(total_loss / loss_count)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('| 에폭 %d | 시간 %d[s] | loss %.2f | 퍼플렉서티 %.2f'\n",
    "                % (epoch + 1, elapsed_time, loss, ppl))\n",
    "            ppl_list.append(float(ppl))\n",
    "            total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e10200c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('iters (x' + str(eval_interval) + ')')\n",
    "plt.ylabel('ppl')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
