{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901b4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from dataset import ptb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5923d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lstmlm:\n",
    "    \n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        \n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed = (rn(V, D) / 100).astype('f')\n",
    "        lstmWx = rn(D, H*4) / np.sqrt(D)\n",
    "        lstmWh = rn(H, H*4) / np.sqrt(H)\n",
    "        lstmb = np.zeros((H*4), dtype='f')\n",
    "        affineW = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affineb = np.zeros(V).astype('f')\n",
    "        \n",
    "        self.params = [embed, lstmWx, lstmWh, lstmb, affineW, affineb]\n",
    "        self.grads = []\n",
    "        self.lstm = []\n",
    "        \n",
    "        self.wordvec_size = wordvec_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.time_idx = 0\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        embed, lstmWx, lstmWh, lstmb, affineW, affineb = self.params\n",
    "                \n",
    "        batch_size, time_size = x.shape\n",
    "        wordvec_size = self.wordvec_size\n",
    "        hidden_size = self.hidden_size\n",
    "        \n",
    "        self.lstm = []\n",
    "        \n",
    "        h_prev = np.zeros((batch_size, hidden_size), dtype='f')\n",
    "        c_prev = np.zeros((batch_size, hidden_size), dtype='f')\n",
    "        hs = np.empty((batch_size, time_size, hidden_size), dtype='f')\n",
    "        for t in range(time_size):\n",
    "            # embed\n",
    "            emb_out = embed[x[:, t]]\n",
    "            \n",
    "            # lstm\n",
    "            A = np.matmul(emb_out, lstmWx) + np.matmul(h_prev, lstmWh) + lstmb\n",
    "            f = A[:, :hidden_size]\n",
    "            g = A[:, hidden_size: 2*hidden_size]\n",
    "            i = A[:, 2*hidden_size: 3*hidden_size]\n",
    "            o = A[:, 3*hidden_size:]\n",
    "\n",
    "            f = self.sigmoid(f)\n",
    "            g = np.tanh(g)\n",
    "            i = self.sigmoid(i)\n",
    "            o = self.sigmoid(o)\n",
    "\n",
    "            c_next = f * c_prev + g * i\n",
    "            h_next = o * np.tanh(c_next)\n",
    "            \n",
    "            hs[:, t, :] = h_next\n",
    "            \n",
    "            self.lstm.append((emb_out, h_prev, c_prev, f, g, i, o, c_next))\n",
    "            c_prev = c_next\n",
    "            h_prev = h_next\n",
    "            \n",
    "        \n",
    "        # affine\n",
    "        affine_out = np.matmul(hs, affineW) + affineb\n",
    "        \n",
    "        # softmax\n",
    "        y = self.softmax(affine_out)\n",
    "        \n",
    "        loss = self.getLoss(y, batch_t)\n",
    "        self.xs = x, hs, affine_out, y\n",
    "\n",
    "        return y, loss\n",
    "    \n",
    "    def backward(self, t):\n",
    "        embed, lstmWx, lstmWh, lstmb, affineW, affineb = self.params\n",
    "        x, hs, affine_out, y = self.xs\n",
    "        \n",
    "        wordvec_size = self.wordvec_size\n",
    "        vocab_size = self.vocab_size\n",
    "        batch_size, time_size = x.shape\n",
    "        \n",
    "        # softmax\n",
    "        y = y.reshape(batch_size * time_size, -1)\n",
    "        t = t.reshape(batch_size * time_size)\n",
    "        y[np.arange(batch_size * time_size), t] -= 1\n",
    "        soft_dout = y\n",
    "        \n",
    "        # affine\n",
    "        affine_dout = np.matmul(soft_dout, affineW.T).reshape(batch_size, time_size, -1) \n",
    "        affinedW = np.matmul(hs.reshape(batch_size * time_size, -1).T, soft_dout) \n",
    "        affinedb = np.sum(soft_dout, axis=0)\n",
    "        \n",
    "        # lstm\n",
    "        lstmdWx = np.zeros_like(lstmWx)\n",
    "        lstmdWh = np.zeros_like(lstmWh)\n",
    "        lstmdb = np.zeros_like(lstmb)\n",
    "        \n",
    "        lstm_douts = np.empty((batch_size, time_size, wordvec_size), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "        for t in reversed(range(time_size)):            \n",
    "            emb_out, h_prev, c_prev, f, g, i, o, c_next = self.lstm[t]\n",
    "            dh_next = affine_dout[:, t, :] + dh\n",
    "            dc_next = dc\n",
    "\n",
    "            tanh_c_next = np.tanh(c_next)\n",
    "            \n",
    "            ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "            \n",
    "            dc_prev = ds * f\n",
    "            \n",
    "            di = ds * g\n",
    "            df = ds * c_prev\n",
    "            do = dh_next * tanh_c_next\n",
    "            dg = ds * i\n",
    "            \n",
    "            di *= i * (1 - i)\n",
    "            df *= f * (1 - f)\n",
    "            do *= o * (1 - o)\n",
    "            dg *= (1 - g ** 2)\n",
    "            \n",
    "            dA = np.hstack((df, dg, di, do))\n",
    "            \n",
    "            dWh = np.matmul(h_prev.T, dA)\n",
    "            dWx = np.matmul(emb_out.T, dA)\n",
    "            db = np.sum(dA, axis=0)\n",
    "            \n",
    "            lstm_douts[:, t, :] = np.matmul(dA, lstmWx.T)\n",
    "            dh_prev = np.matmul(dA, lstmWh.T)\n",
    "        \n",
    "            lstmdWx += dWx\n",
    "            lstmdWh += dWh\n",
    "            lstmdb += db\n",
    "            dh = dh_prev\n",
    "            dc = dc_prev\n",
    "        \n",
    "        # embed\n",
    "        embed_dout = np.zeros_like(embed)\n",
    "        for t in range(time_size):\n",
    "            np.add.at(embed_dout, x[:, t], lstm_douts[:, t, :])\n",
    "        \n",
    "        self.grads = embed_dout, lstmdWx, lstmdWh, lstmdb, affinedW, affinedb\n",
    "        \n",
    "        \n",
    "    def softmax(self, y):\n",
    "        y = y - np.max(y)\n",
    "        y = np.exp(y)\n",
    "        y = y / y.sum(axis=2, keepdims=True)\n",
    "        return y\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def update(self, lr):\n",
    "        for i in range(len(self.params)):\n",
    "            self.params[i] -= self.grads[i] * lr      \n",
    "            \n",
    "    def getLoss(self, y, t):\n",
    "        N, T, V = y.shape\n",
    "\n",
    "        y = y.reshape(N * T, V)\n",
    "        t = t.reshape(N * T)\n",
    "\n",
    "        ls = np.log(y[np.arange(N * T), t])\n",
    "        return -np.sum(ls) / (N * T)\n",
    "    \n",
    "    def get_batch(self, x, t, batch_size, time_size):\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "\n",
    "        data_size = len(x)\n",
    "        jump = data_size // batch_size\n",
    "        offsets = [i * jump for i in range(batch_size)] \n",
    "        for time in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, time] = x[(offset + self.time_idx) % data_size]\n",
    "                batch_t[i, time] = t[(offset + self.time_idx) % data_size]\n",
    "            self.time_idx += 1\n",
    "        return batch_x, batch_t\n",
    "    \n",
    "    def clip_grads(self, max_norm):\n",
    "        grads = self.grads\n",
    "        total_norm = 0\n",
    "        \n",
    "        for grad in grads:\n",
    "            total_norm += np.sum(grad**2)\n",
    "            \n",
    "        total_norm = np.sqrt(total_norm)\n",
    "        \n",
    "        rate = max_norm / (total_norm + 1e-6)\n",
    "        \n",
    "        if rate  < 1:\n",
    "            for grad in grads:\n",
    "                grad *= rate\n",
    "        self.grads = grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52e1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1] \n",
    "ts = corpus[1:]  \n",
    "\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  \n",
    "time_size = 35  \n",
    "lr = 20.0\n",
    "max_epoch = 1\n",
    "max_iters = len(xs) // (batch_size * time_size)\n",
    "eval_interval = 20\n",
    "max_grad = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b15a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lstmlm(vocab_size, wordvec_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2cd95d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | iters 1 | time 0[s] | loss 9.21 | ppl 9999.82\n",
      "| epoch 1 | iters 21 | time 7[s] | loss 6.97 | ppl 1998.49\n",
      "| epoch 1 | iters 41 | time 15[s] | loss 7.26 | ppl 1243.30\n",
      "| epoch 1 | iters 61 | time 22[s] | loss 6.81 | ppl 958.78\n",
      "| epoch 1 | iters 81 | time 30[s] | loss 6.45 | ppl 705.12\n",
      "| epoch 1 | iters 101 | time 39[s] | loss 6.26 | ppl 587.73\n",
      "| epoch 1 | iters 121 | time 47[s] | loss 6.36 | ppl 579.91\n",
      "| epoch 1 | iters 141 | time 56[s] | loss 6.19 | ppl 535.20\n",
      "| epoch 1 | iters 161 | time 64[s] | loss 6.17 | ppl 518.43\n",
      "| epoch 1 | iters 181 | time 72[s] | loss 6.28 | ppl 524.64\n",
      "| epoch 1 | iters 201 | time 81[s] | loss 6.04 | ppl 447.24\n",
      "| epoch 1 | iters 221 | time 89[s] | loss 6.02 | ppl 426.38\n",
      "| epoch 1 | iters 241 | time 97[s] | loss 5.86 | ppl 397.71\n",
      "| epoch 1 | iters 261 | time 106[s] | loss 5.95 | ppl 412.23\n",
      "| epoch 1 | iters 281 | time 114[s] | loss 5.64 | ppl 403.13\n",
      "| epoch 1 | iters 301 | time 123[s] | loss 5.68 | ppl 350.76\n",
      "| epoch 1 | iters 321 | time 131[s] | loss 5.33 | ppl 301.10\n",
      "| epoch 1 | iters 341 | time 140[s] | loss 6.16 | ppl 358.67\n",
      "| epoch 1 | iters 361 | time 148[s] | loss 5.71 | ppl 368.11\n",
      "| epoch 1 | iters 381 | time 157[s] | loss 5.31 | ppl 298.85\n",
      "| epoch 1 | iters 401 | time 165[s] | loss 5.95 | ppl 319.85\n",
      "| epoch 1 | iters 421 | time 173[s] | loss 5.99 | ppl 307.47\n",
      "| epoch 1 | iters 441 | time 180[s] | loss 5.48 | ppl 298.33\n",
      "| epoch 1 | iters 461 | time 188[s] | loss 5.96 | ppl 298.73\n",
      "| epoch 1 | iters 481 | time 195[s] | loss 5.76 | ppl 277.78\n",
      "| epoch 1 | iters 501 | time 203[s] | loss 5.73 | ppl 290.76\n",
      "| epoch 1 | iters 521 | time 210[s] | loss 5.47 | ppl 278.65\n",
      "| epoch 1 | iters 541 | time 219[s] | loss 5.87 | ppl 291.38\n",
      "| epoch 1 | iters 561 | time 229[s] | loss 5.51 | ppl 258.08\n",
      "| epoch 1 | iters 581 | time 238[s] | loss 5.71 | ppl 235.87\n",
      "| epoch 1 | iters 601 | time 247[s] | loss 5.74 | ppl 309.47\n",
      "| epoch 1 | iters 621 | time 256[s] | loss 5.45 | ppl 283.25\n",
      "| epoch 1 | iters 641 | time 266[s] | loss 5.40 | ppl 262.50\n",
      "| epoch 1 | iters 661 | time 279[s] | loss 5.41 | ppl 248.53\n",
      "| epoch 1 | iters 681 | time 287[s] | loss 5.59 | ppl 208.33\n",
      "| epoch 1 | iters 701 | time 297[s] | loss 5.56 | ppl 232.77\n",
      "| epoch 1 | iters 721 | time 307[s] | loss 5.27 | ppl 240.23\n",
      "| epoch 1 | iters 741 | time 317[s] | loss 5.23 | ppl 204.83\n",
      "| epoch 1 | iters 761 | time 327[s] | loss 5.31 | ppl 211.72\n",
      "| epoch 1 | iters 781 | time 335[s] | loss 5.06 | ppl 203.81\n",
      "| epoch 1 | iters 801 | time 341[s] | loss 5.48 | ppl 226.23\n",
      "| epoch 1 | iters 821 | time 348[s] | loss 5.51 | ppl 212.24\n",
      "| epoch 1 | iters 841 | time 354[s] | loss 5.44 | ppl 212.84\n",
      "| epoch 1 | iters 861 | time 360[s] | loss 5.09 | ppl 210.68\n",
      "| epoch 1 | iters 881 | time 367[s] | loss 5.12 | ppl 192.94\n",
      "| epoch 1 | iters 901 | time 375[s] | loss 5.39 | ppl 243.15\n",
      "| epoch 1 | iters 921 | time 381[s] | loss 5.46 | ppl 217.14\n",
      "| epoch 1 | iters 941 | time 389[s] | loss 5.33 | ppl 219.05\n",
      "| epoch 1 | iters 961 | time 400[s] | loss 5.36 | ppl 231.35\n",
      "| epoch 1 | iters 981 | time 409[s] | loss 5.38 | ppl 219.72\n",
      "| epoch 1 | iters 1001 | time 419[s] | loss 5.30 | ppl 185.39\n",
      "| epoch 1 | iters 1021 | time 428[s] | loss 5.28 | ppl 216.76\n",
      "| epoch 1 | iters 1041 | time 435[s] | loss 4.98 | ppl 201.93\n",
      "| epoch 1 | iters 1061 | time 444[s] | loss 5.02 | ppl 186.35\n",
      "| epoch 1 | iters 1081 | time 453[s] | loss 5.18 | ppl 160.02\n",
      "| epoch 1 | iters 1101 | time 460[s] | loss 5.39 | ppl 179.64\n",
      "| epoch 1 | iters 1121 | time 468[s] | loss 5.29 | ppl 220.95\n",
      "| epoch 1 | iters 1141 | time 475[s] | loss 5.46 | ppl 200.26\n",
      "| epoch 1 | iters 1161 | time 484[s] | loss 5.16 | ppl 188.78\n",
      "| epoch 1 | iters 1181 | time 492[s] | loss 5.03 | ppl 184.28\n",
      "| epoch 1 | iters 1201 | time 499[s] | loss 5.16 | ppl 156.88\n",
      "| epoch 1 | iters 1221 | time 507[s] | loss 5.34 | ppl 154.81\n",
      "| epoch 1 | iters 1241 | time 516[s] | loss 5.38 | ppl 180.57\n",
      "| epoch 1 | iters 1261 | time 525[s] | loss 5.08 | ppl 165.20\n",
      "| epoch 1 | iters 1281 | time 533[s] | loss 5.39 | ppl 171.77\n",
      "| epoch 1 | iters 1301 | time 541[s] | loss 5.36 | ppl 216.38\n",
      "| epoch 1 | iters 1321 | time 548[s] | loss 5.37 | ppl 204.49\n"
     ]
    }
   ],
   "source": [
    "ppl_list = []\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "start_time = time.time()\n",
    "model.time_idx = 0\n",
    "for epoch in range(max_epoch):\n",
    "    for iters in range(max_iters):\n",
    "        batch_x, batch_t = model.get_batch(xs, ts, batch_size, time_size)\n",
    "\n",
    "        y, loss = model.forward(batch_x, batch_t)\n",
    "        model.backward(batch_t)\n",
    "        model.clip_grads(max_grad)\n",
    "        model.update(lr)\n",
    "        \n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "        if ((iters % eval_interval) == 0):\n",
    "            ppl = np.exp(total_loss / loss_count)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('| epoch %d | iters %d | time %d[s] | loss %.2f | ppl %.2f'\n",
    "                % (epoch + 1, iters + 1, elapsed_time, loss, ppl))\n",
    "            ppl_list.append(float(ppl))\n",
    "            total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e10200c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = np.arange(len(ppl_list))\n",
    "plt.plot(p, ppl_list, label='train')\n",
    "plt.xlabel('iters (x' + str(eval_interval) + ')')\n",
    "plt.ylabel('ppl')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
