{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901b4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from dataset import ptb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5923d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lstmlm:\n",
    "    \n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        \n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed = (rn(V, D) / 100).astype('f')\n",
    "        lstmWx = rn(D, H*4) / np.sqrt(D)\n",
    "        lstmWh = rn(H, H*4) / np.sqrt(H)\n",
    "        lstmb = np.zeros((H*4), dtype='f')\n",
    "        affineW = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affineb = np.zeros(V).astype('f')\n",
    "        \n",
    "        self.params = [embed, lstmWx, lstmWh, lstmb, affineW, affineb]\n",
    "        self.grads = []\n",
    "        self.lstm = []\n",
    "        \n",
    "        self.wordvec_size = wordvec_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.time_idx = 0\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        embed, lstmWx, lstmWh, lstmb, affineW, affineb = self.params\n",
    "                \n",
    "        batch_size, time_size = x.shape\n",
    "        wordvec_size = self.wordvec_size\n",
    "        hidden_size = self.hidden_size\n",
    "        \n",
    "        self.lstm = []\n",
    "        \n",
    "        h_prev = np.zeros((batch_size, hidden_size), dtype='f')\n",
    "        c_prev = np.zeros((batch_size, hidden_size), dtype='f')\n",
    "        hs = np.empty((batch_size, time_size, hidden_size), dtype='f')\n",
    "        for t in range(time_size):\n",
    "            # embed\n",
    "            emb_out = embed[x[:, t]]\n",
    "            \n",
    "            # lstm\n",
    "            A = np.matmul(emb_out, lstmWx) + np.matmul(h_prev, lstmWh) + lstmb\n",
    "            f = A[:, :hidden_size]\n",
    "            g = A[:, hidden_size: 2*hidden_size]\n",
    "            i = A[:, 2*hidden_size: 3*hidden_size]\n",
    "            o = A[:, 3*hidden_size:]\n",
    "\n",
    "            f = self.sigmoid(f)\n",
    "            g = np.tanh(g)\n",
    "            i = self.sigmoid(i)\n",
    "            o = self.sigmoid(o)\n",
    "\n",
    "            c_next = f * c_prev + g * i\n",
    "            h_next = o * np.tanh(c_next)\n",
    "            \n",
    "            hs[:, t, :] = h_next\n",
    "            \n",
    "            self.lstm.append((emb_out, h_prev, c_prev, f, g, i, o, c_next))\n",
    "            c_prev = c_next\n",
    "            h_prev = h_next\n",
    "            \n",
    "        \n",
    "        # affine\n",
    "        affine_out = np.matmul(hs, affineW) + affineb\n",
    "        \n",
    "        # softmax\n",
    "        y = self.softmax(affine_out)\n",
    "        \n",
    "        loss = self.getLoss(y, batch_t)\n",
    "        self.xs = x, hs, affine_out, y\n",
    "\n",
    "        return y, loss\n",
    "    \n",
    "    def backward(self, t):\n",
    "        embed, lstmWx, lstmWh, lstmb, affineW, affineb = self.params\n",
    "        x, hs, affine_out, y = self.xs\n",
    "        \n",
    "        wordvec_size = self.wordvec_size\n",
    "        vocab_size = self.vocab_size\n",
    "        batch_size, time_size = x.shape\n",
    "        \n",
    "        # softmax\n",
    "        y = y.reshape(batch_size * time_size, -1)\n",
    "        t = t.reshape(batch_size * time_size)\n",
    "        y[np.arange(batch_size * time_size), t] -= 1\n",
    "        soft_dout = y\n",
    "        \n",
    "        # affine\n",
    "        affine_dout = np.matmul(soft_dout, affineW.T).reshape(batch_size, time_size, -1) # (b, t, h)\n",
    "        affinedW = np.matmul(hs.reshape(batch_size * time_size, -1).T, soft_dout) # (h, v)\n",
    "        affinedb = np.sum(soft_dout, axis=0)\n",
    "        \n",
    "        # lstm\n",
    "        lstmdWx = np.zeros_like(lstmWx)\n",
    "        lstmdWh = np.zeros_like(lstmWh)\n",
    "        lstmdb = np.zeros_like(lstmb)\n",
    "        \n",
    "        lstm_douts = np.empty((batch_size, time_size, wordvec_size), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "        for t in reversed(range(time_size)):            \n",
    "            emb_out, h_prev, c_prev, f, g, i, o, c_next = self.lstm[t]\n",
    "            dh_next = affine_dout[:, t, :] + dh\n",
    "            dc_next = dc\n",
    "\n",
    "            tanh_c_next = np.tanh(c_next)\n",
    "            \n",
    "            ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "            \n",
    "            dc_prev = ds * f\n",
    "            \n",
    "            di = ds * g\n",
    "            df = ds * c_prev\n",
    "            do = dh_next * tanh_c_next\n",
    "            dg = ds * i\n",
    "            \n",
    "            di *= i * (1 - i)\n",
    "            df *= f * (1 - f)\n",
    "            do *= o * (1 - o)\n",
    "            dg *= (1 - g ** 2)\n",
    "            \n",
    "            dA = np.hstack((df, dg, di, do))\n",
    "            \n",
    "            dWh = np.matmul(h_prev.T, dA)\n",
    "            dWx = np.matmul(emb_out.T, dA)\n",
    "            db = np.sum(dA, axis=0)\n",
    "            \n",
    "            lstm_douts[:, t, :] = np.matmul(dA, lstmWx.T)\n",
    "            dh_prev = np.matmul(dA, lstmWh.T)\n",
    "        \n",
    "            lstmdWx += dWx\n",
    "            lstmdWh += dWh\n",
    "            lstmdb += db\n",
    "            dh = dh_prev\n",
    "            dc = dc_prev\n",
    "        \n",
    "        # embed\n",
    "        embed_dout = np.zeros_like(embed)\n",
    "        for t in range(time_size):\n",
    "            np.add.at(embed_dout, x[:, t], lstm_douts[:, t, :])\n",
    "        \n",
    "        self.grads = embed_dout, lstmdWx, lstmdWh, lstmdb, affinedW, affinedb\n",
    "        \n",
    "        \n",
    "    def softmax(self, y):\n",
    "        y = y - np.max(y)\n",
    "        y = np.exp(y)\n",
    "        y = y / y.sum(axis=2, keepdims=True)\n",
    "        return y\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def update(self, lr):\n",
    "        for i in range(len(self.params)):\n",
    "            self.params[i] -= self.grads[i] * lr      \n",
    "            \n",
    "    def getLoss(self, y, t):\n",
    "        N, T, V = y.shape\n",
    "\n",
    "        y = y.reshape(N * T, V)\n",
    "        t = t.reshape(N * T)\n",
    "\n",
    "        ls = np.log(y[np.arange(N * T), t])\n",
    "        return -np.sum(ls) / (N * T)\n",
    "    \n",
    "    def get_batch(self, x, t, batch_size, time_size):\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "\n",
    "        data_size = len(x)\n",
    "        jump = data_size // batch_size\n",
    "        offsets = [i * jump for i in range(batch_size)] \n",
    "        for time in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, time] = x[(offset + self.time_idx) % data_size]\n",
    "                batch_t[i, time] = t[(offset + self.time_idx) % data_size]\n",
    "            self.time_idx += 1\n",
    "        return batch_x, batch_t\n",
    "    \n",
    "    def clip_grads(self, max_norm):\n",
    "        grads = self.grads\n",
    "        total_norm = 0\n",
    "        \n",
    "        for grad in grads:\n",
    "            total_norm += np.sum(grad**2)\n",
    "            \n",
    "        total_norm = np.sqrt(total_norm)\n",
    "        \n",
    "        rate = max_norm / (total_norm + 1e-6)\n",
    "        \n",
    "        if rate  < 1:\n",
    "            for grad in grads:\n",
    "                grad *= rate\n",
    "        self.grads = grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52e1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1] \n",
    "ts = corpus[1:]  \n",
    "\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  \n",
    "time_size = 35  \n",
    "lr = 20.0\n",
    "max_epoch = 1\n",
    "max_iters = len(xs) // (batch_size * time_size)\n",
    "eval_interval = 20\n",
    "max_grad = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b15a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lstmlm(vocab_size, wordvec_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2cd95d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | iters 1 | time 0[s] | loss 9.21 | ppl 10000.31\n",
      "| epoch 1 | iters 21 | time 6[s] | loss 7.01 | ppl 2071.21\n",
      "| epoch 1 | iters 41 | time 13[s] | loss 7.20 | ppl 1251.01\n",
      "| epoch 1 | iters 61 | time 20[s] | loss 6.82 | ppl 927.83\n",
      "| epoch 1 | iters 81 | time 28[s] | loss 6.40 | ppl 683.43\n",
      "| epoch 1 | iters 101 | time 35[s] | loss 6.22 | ppl 559.88\n",
      "| epoch 1 | iters 121 | time 42[s] | loss 6.27 | ppl 575.35\n",
      "| epoch 1 | iters 141 | time 49[s] | loss 6.17 | ppl 511.68\n",
      "| epoch 1 | iters 161 | time 55[s] | loss 5.92 | ppl 502.57\n",
      "| epoch 1 | iters 181 | time 62[s] | loss 6.28 | ppl 507.45\n",
      "| epoch 1 | iters 201 | time 69[s] | loss 6.01 | ppl 439.65\n",
      "| epoch 1 | iters 221 | time 75[s] | loss 6.06 | ppl 423.74\n",
      "| epoch 1 | iters 241 | time 83[s] | loss 5.86 | ppl 395.45\n",
      "| epoch 1 | iters 261 | time 91[s] | loss 5.96 | ppl 405.84\n",
      "| epoch 1 | iters 281 | time 98[s] | loss 5.66 | ppl 401.09\n",
      "| epoch 1 | iters 301 | time 104[s] | loss 5.68 | ppl 349.60\n",
      "| epoch 1 | iters 321 | time 111[s] | loss 5.33 | ppl 302.96\n",
      "| epoch 1 | iters 341 | time 118[s] | loss 6.11 | ppl 355.94\n",
      "| epoch 1 | iters 361 | time 125[s] | loss 5.67 | ppl 368.27\n",
      "| epoch 1 | iters 381 | time 133[s] | loss 5.26 | ppl 297.05\n",
      "| epoch 1 | iters 401 | time 141[s] | loss 5.98 | ppl 320.65\n",
      "| epoch 1 | iters 421 | time 149[s] | loss 5.91 | ppl 307.41\n",
      "| epoch 1 | iters 441 | time 155[s] | loss 5.46 | ppl 298.05\n",
      "| epoch 1 | iters 461 | time 162[s] | loss 5.96 | ppl 293.98\n",
      "| epoch 1 | iters 481 | time 169[s] | loss 5.77 | ppl 276.43\n",
      "| epoch 1 | iters 501 | time 176[s] | loss 5.73 | ppl 293.04\n",
      "| epoch 1 | iters 521 | time 183[s] | loss 5.50 | ppl 278.79\n",
      "| epoch 1 | iters 541 | time 191[s] | loss 5.84 | ppl 296.35\n",
      "| epoch 1 | iters 561 | time 198[s] | loss 5.53 | ppl 260.26\n",
      "| epoch 1 | iters 581 | time 210[s] | loss 5.71 | ppl 235.91\n",
      "| epoch 1 | iters 601 | time 220[s] | loss 5.70 | ppl 309.41\n",
      "| epoch 1 | iters 621 | time 231[s] | loss 5.45 | ppl 285.66\n",
      "| epoch 1 | iters 641 | time 239[s] | loss 5.38 | ppl 261.10\n",
      "| epoch 1 | iters 661 | time 249[s] | loss 5.42 | ppl 251.72\n",
      "| epoch 1 | iters 681 | time 257[s] | loss 5.60 | ppl 208.19\n",
      "| epoch 1 | iters 701 | time 265[s] | loss 5.52 | ppl 233.16\n",
      "| epoch 1 | iters 721 | time 272[s] | loss 5.27 | ppl 240.27\n",
      "| epoch 1 | iters 741 | time 279[s] | loss 5.26 | ppl 207.79\n",
      "| epoch 1 | iters 761 | time 286[s] | loss 5.36 | ppl 214.97\n",
      "| epoch 1 | iters 781 | time 293[s] | loss 5.07 | ppl 202.98\n",
      "| epoch 1 | iters 801 | time 300[s] | loss 5.45 | ppl 228.38\n",
      "| epoch 1 | iters 821 | time 307[s] | loss 5.48 | ppl 213.88\n",
      "| epoch 1 | iters 841 | time 314[s] | loss 5.44 | ppl 214.38\n",
      "| epoch 1 | iters 861 | time 321[s] | loss 5.06 | ppl 209.24\n",
      "| epoch 1 | iters 881 | time 329[s] | loss 5.04 | ppl 192.04\n",
      "| epoch 1 | iters 901 | time 336[s] | loss 5.39 | ppl 241.55\n",
      "| epoch 1 | iters 921 | time 343[s] | loss 5.46 | ppl 215.66\n",
      "| epoch 1 | iters 941 | time 351[s] | loss 5.36 | ppl 218.26\n",
      "| epoch 1 | iters 961 | time 358[s] | loss 5.37 | ppl 233.25\n",
      "| epoch 1 | iters 981 | time 365[s] | loss 5.37 | ppl 219.08\n",
      "| epoch 1 | iters 1001 | time 373[s] | loss 5.34 | ppl 186.32\n",
      "| epoch 1 | iters 1021 | time 383[s] | loss 5.24 | ppl 215.22\n",
      "| epoch 1 | iters 1041 | time 391[s] | loss 4.94 | ppl 201.80\n",
      "| epoch 1 | iters 1061 | time 400[s] | loss 5.03 | ppl 187.09\n",
      "| epoch 1 | iters 1081 | time 407[s] | loss 5.23 | ppl 159.17\n",
      "| epoch 1 | iters 1101 | time 416[s] | loss 5.38 | ppl 179.34\n",
      "| epoch 1 | iters 1121 | time 426[s] | loss 5.28 | ppl 220.50\n",
      "| epoch 1 | iters 1141 | time 437[s] | loss 5.43 | ppl 200.08\n",
      "| epoch 1 | iters 1161 | time 446[s] | loss 5.13 | ppl 189.64\n",
      "| epoch 1 | iters 1181 | time 457[s] | loss 5.01 | ppl 184.06\n",
      "| epoch 1 | iters 1201 | time 467[s] | loss 5.14 | ppl 156.34\n",
      "| epoch 1 | iters 1221 | time 477[s] | loss 5.30 | ppl 153.32\n",
      "| epoch 1 | iters 1241 | time 489[s] | loss 5.38 | ppl 181.23\n",
      "| epoch 1 | iters 1261 | time 499[s] | loss 5.09 | ppl 166.76\n",
      "| epoch 1 | iters 1281 | time 513[s] | loss 5.42 | ppl 171.97\n",
      "| epoch 1 | iters 1301 | time 525[s] | loss 5.42 | ppl 216.72\n",
      "| epoch 1 | iters 1321 | time 536[s] | loss 5.38 | ppl 204.74\n"
     ]
    }
   ],
   "source": [
    "ppl_list = []\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "start_time = time.time()\n",
    "model.time_idx = 0\n",
    "for epoch in range(max_epoch):\n",
    "    for iters in range(max_iters):\n",
    "        batch_x, batch_t = model.get_batch(xs, ts, batch_size, time_size)\n",
    "\n",
    "        y, loss = model.forward(batch_x, batch_t)\n",
    "        model.backward(batch_t)\n",
    "        model.clip_grads(max_grad)\n",
    "        model.update(lr)\n",
    "        \n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "        if ((iters % eval_interval) == 0):\n",
    "            ppl = np.exp(total_loss / loss_count)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print('| epoch %d | iters %d | time %d[s] | loss %.2f | ppl %.2f'\n",
    "                % (epoch + 1, iters + 1, elapsed_time, loss, ppl))\n",
    "            ppl_list.append(float(ppl))\n",
    "            total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e10200c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAiRElEQVR4nO3df3Rc5X3n8fd35s5cSbZ+2ZaNkQyGYAOGEAiucUpK0tAE2qaFc9psnN0UtkvrLqXd9Nd2Ybdnc7qnPk1Oc9KEbcM5lKSQn5Qm3cI2P6lDoWmzEAEBAwbsYrCFjSX/lKzfo/nuH/cZeSSPzcxIo5HQ53XOnJl55t47XylEHz/Pc+9zzd0RERGpVqreBYiIyMKmIBERkRlRkIiIyIwoSEREZEYUJCIiMiNRvQuYaytWrPC1a9fWuwwRkQXlySefPOTuHaU+W3RBsnbtWrq7u+tdhojIgmJmr53uMw1tiYjIjChIRERkRhQkIiIyIwoSERGZEQWJiIjMSM2CxMy+YGa9ZvZcUdsyM3vYzHaF5/aiz+4ws91m9pKZXVfUfqWZ7Qif3WlmFtpjM/ub0P64ma2t1c8iIiKnV8seyb3A9dPabge2u/s6YHt4j5ltALYAl4R9Pmdm6bDPXcBWYF14FI55C3DU3S8A/hz4ZM1+EhEROa2aBYm7PwYcmdZ8A3BfeH0fcGNR+/3uPurue4DdwCYzWw20uPsPPVnv/ovT9ikc6+vAtYXeSi386NUjfOq7L5GbyNfqK0REFqS5niNZ5e4HAMLzytDeCewr2q4ntHWG19Pbp+zj7jngOLC81Jea2VYz6zaz7r6+vqoK//HeY/zFI7sZzSlIRESKzZfJ9lI9CT9D+5n2ObXR/W533+juGzs6Sl7h/6ayUfKrUpCIiEw110FyMAxXEZ57Q3sPsKZouy5gf2jvKtE+ZR8zi4BWTh1KmzWFIBlTkIiITDHXQfIQcHN4fTPwYFH7lnAm1nkkk+pPhOGvATPbHOY/bpq2T+FYvwx832t43+B4skcyUauvEBFZkGq2aKOZfQ14L7DCzHqAjwOfAB4ws1uAvcCHANz9eTN7AHgByAG3uXvhL/atJGeANQLfDg+AzwNfMrPdJD2RLbX6WUA9EhGR06lZkLj7R07z0bWn2X4bsK1EezdwaYn2EUIQzYU4Ss5G1hyJiMhU82Wyfd7TZLuISGkKkjJl0xraEhEpRUFSpjijyXYRkVIUJGVSj0REpDQFSZkaMpojEREpRUFSpmw6OWtLPRIRkakUJGUqzJGMadFGEZEpFCRlKsyRjI5rsl1EpJiCpEyTV7arRyIiMoWCpEyTa22NK0hERIopSMoUpVOkTD0SEZHpFCQViKO0Tv8VEZlGQVKBbJTS6b8iItMoSCqQjVLqkYiITKMgqUAcpbTWlojINAqSCmhoS0TkVAqSCmiyXUTkVAqSCqhHIiJyKgVJBeK05khERKZTkFQgzqhHIiIynYKkAtl0Sle2i4hMoyCpQJxJaa0tEZFpFCQVUI9ERORUCpIKxFFaPRIRkWkUJBXIRuqRiIhMpyCpgK4jERE5lYKkAlprS0TkVAqSCmSjFOMTTj7v9S5FRGTeUJBUII7SgO6SKCJSTEFSgWzhvu2aJxERmaQgqcDJINE8iYhIQV2CxMx+18yeN7PnzOxrZtZgZsvM7GEz2xWe24u2v8PMdpvZS2Z2XVH7lWa2I3x2p5lZLeuOQ5DozC0RkZPmPEjMrBP4L8BGd78USANbgNuB7e6+Dtge3mNmG8LnlwDXA58zs3Q43F3AVmBdeFxfy9oVJCIip6rX0FYENJpZBDQB+4EbgPvC5/cBN4bXNwD3u/uou+8BdgObzGw10OLuP3R3B75YtE9NxJojERE5xZwHibu/DnwK2AscAI67+/eAVe5+IGxzAFgZdukE9hUdoie0dYbX09tPYWZbzazbzLr7+vqqrj2rHomIyCnqMbTVTtLLOA84G1hiZh890y4l2vwM7ac2ut/t7hvdfWNHR0elJU8qnP6rHomIyEn1GNr6GWCPu/e5+zjwd8BPAgfDcBXhuTds3wOsKdq/i2QorCe8nt5eM+qRiIicqh5BshfYbGZN4Syra4GdwEPAzWGbm4EHw+uHgC1mFpvZeSST6k+E4a8BM9scjnNT0T41kU2HIJnQ6b8iIgXRXH+huz9uZl8HngJywNPA3cBS4AEzu4UkbD4Utn/ezB4AXgjb3+buhb/ktwL3Ao3At8OjZuJMmGzXUvIiIpPmPEgA3P3jwMenNY+S9E5Kbb8N2FaivRu4dNYLPI2TPRIFiYhIga5sr0CcCZPt6pGIiExSkFSg0CMZVY9ERGSSgqQCk2ttjWuyXUSkQEFSgcklUtQjERGZpCCpwORku64jERGZpCCpQCplZNMpXdkuIlJEQVKhbJRSj0REpIiCpEJxlNKNrUREiihIKqQeiYjIVAqSCmUjzZGIiBRTkFQoVo9ERGQKBUmFNLQlIjKVgqRCcZTW0JaISBEFSYWyafVIRESKKUgqlNXpvyIiUyhIKhTrrC0RkSkUJBXKRikt2igiUkRBUqE4SuvGViIiRRQkFVKPRERkKgVJheIopRtbiYgUUZBUKFaPRERkCgVJhQprbbl7vUsREZkXFCQViqMU7pDLK0hEREBBUrFspNvtiogUU5BUKI7SALooUUQkUJBUSD0SEZGpFCQVyqaTX5nW2xIRSShIKhRn1CMRESmmIKnQyR6JgkREBBQkFYszmmwXESmmIKlQoUeioS0RkURdgsTM2szs62b2opntNLN3mdkyM3vYzHaF5/ai7e8ws91m9pKZXVfUfqWZ7Qif3WlmVuvaC3MkmmwXEUnUq0fyWeA77n4R8A5gJ3A7sN3d1wHbw3vMbAOwBbgEuB74nJmlw3HuArYC68Lj+loXrh6JiMhUcx4kZtYCXAN8HsDdx9z9GHADcF/Y7D7gxvD6BuB+dx919z3AbmCTma0GWtz9h54sfPXFon1qJo402S4iUqwePZLzgT7gr83saTO7x8yWAKvc/QBAeF4Ztu8E9hXt3xPaOsPr6e01VbiyXT0SEZFEPYIkAt4J3OXuVwCDhGGs0yg17+FnaD/1AGZbzazbzLr7+voqrXeKySvbtZS8iAhQnyDpAXrc/fHw/uskwXIwDFcRnnuLtl9TtH8XsD+0d5VoP4W73+3uG919Y0dHx4yKnxza0s2tRESAOgSJu78B7DOzC0PTtcALwEPAzaHtZuDB8PohYIuZxWZ2Hsmk+hNh+GvAzDaHs7VuKtqnZtQjERGZKqrT9/428BUzywKvAL9KEmoPmNktwF7gQwDu/ryZPUASNjngNncvdAduBe4FGoFvh0dNZSd7JAoSERGoU5C4+4+BjSU+uvY0228DtpVo7wYundXi3kSUMlKmHomISIGubK+QmU3ebldERBQkVYmjtE7/FREJFCRVUI9EROQkBUkV4iiltbZERAIFSRWyUUpDWyIigYKkCtm0hrZERAoUJFWIM5psFxEpUJBUIU5rjkREpEBBUoU4ozkSEZGCM17Zbma/d6bP3f3Ts1vOwpBNpziqK9tFRIA3XyKleU6qWGCyUUprbYmIBGcMEnf/47kqZCGJo5TW2hIRCcqaIzGz883s/5pZn5n1mtmDZnZ+rYubr9QjERE5qdzJ9q8CDwCrgbOBvwW+Vqui5rs4SqtHIiISlBsk5u5fcvdceHyZ09zWdjHQle0iIieVez+SR8zsDpJeiAMfBr5pZssA3P1Ijeqbl7TWlojISeUGyYfD86+HZwvP/4kkWBbVfEk2SjE+4eTzTiplb76DiMhbWLlBsgH4TeDdJMHxz8Bd7j5Sq8Lms+L7tjek0nWuRkSkvsqdI7kPuBi4E/jf4fUXa1XUfBdHSXho4UYRkfJ7JBe6+zuK3j9iZs/UoqCFoNAjSeZJMvUtRkSkzsrtkTxtZpsLb8zsKuBfalPS/BcXhrbUIxERKbtHchVwk5ntDe/PAXaa2Q7A3f2ymlQ3TylIREROKjdIrq9pFQtMNl0Y2lKQiIiUFSTu/lqtC1lI4ox6JCIiBbofSRWyaZ21JSJSoCCpgnokIiInKUiqcHKORMukiIgoSKqgHomIyEkKkioUeiRaSl5EREFSlckr23VzKxERBUk1JtfaUo9ERERBUo2TPRJNtouI1C1IzCxtZk+b2T+E98vM7GEz2xWe24u2vcPMdpvZS2Z2XVH7lWa2I3x2p5nNyc1B4khzJCIiBfXskXwM2Fn0/nZgu7uvA7aH95jZBmALcAnJUi2fM7PCTUDuArYC68JjTpZymZxs11lbIiL1CRIz6wJ+HrinqPkGkvueEJ5vLGq/391H3X0PsBvYZGargRZ3/6G7O8n9UW5kDqRSRiZturJdRIT69Ug+A/whUPyXeJW7HwAIzytDeyewr2i7ntDWGV5Pbz+FmW01s24z6+7r65uVHyCO0uqRiIhQhyAxsw8Cve7+ZLm7lGjzM7Sf2uh+t7tvdPeNHR0dZX7tmWWjlK5sFxGh/GXkZ9PVwC+a2c8BDUCLmX0ZOGhmq939QBi26g3b9wBrivbvAvaH9q4S7XMijlLqkYiIUIceibvf4e5d7r6WZBL9++7+UeAh4Oaw2c3Ag+H1Q8AWM4vN7DySSfUnwvDXgJltDmdr3VS0T80lPRIFiYhIPXokp/MJ4AEzuwXYC3wIwN2fN7MHgBeAHHCbuxfGlG4F7gUagW+Hx5xQj0REJFHXIHH3fwL+Kbw+DFx7mu22AdtKtHcDl9auwtPLKkhERABd2V61bFpDWyIioCCpmk7/FRFJKEiqpNN/RUQSCpIqxTprS0QEUJBULRultGijiAgKkqplo5RubCUigoKkanGUVo9ERAQFSdXiKKUbW4mIoCCpWqw5EhERQEFStcJaW8mtUEREFi8FSZXiKIU75PIKEhFZ3BQkVcpGut2uiAgoSKpWuG+7LkoUkcVOQVKlOJMG1CMREVGQVOlkj0SnAIvI4qYgqVKc0RyJiAgoSKqmORIRkYSCpEqFs7YUJCKy2ClIqhRHmmwXEQEFSdVO9kg02S4ii5uCpEqxLkgUEQEUJFWLNUciIgIoSKqmORIRkYSCpEqTa21pKXkRWeQUJFWanGzXza1EZJFTkFQpVo9ERARQkFTtZI9EQSIii5uCpEpRykiZeiQiIgqSKpnZ5O12RUQWMwXJDGTTKZ3+KyKLnoJkBuJMWj0SEVn05jxIzGyNmT1iZjvN7Hkz+1hoX2ZmD5vZrvDcXrTPHWa228xeMrPritqvNLMd4bM7zczm8mfJplNaa0tEFr169EhywO+7+8XAZuA2M9sA3A5sd/d1wPbwnvDZFuAS4Hrgc2aWDse6C9gKrAuP6+fyB2luiOgbGJ3LrxQRmXfmPEjc/YC7PxVeDwA7gU7gBuC+sNl9wI3h9Q3A/e4+6u57gN3AJjNbDbS4+w/d3YEvFu0zJzafv5wfvXqEEV2UKCKLWF3nSMxsLXAF8Diwyt0PQBI2wMqwWSewr2i3ntDWGV5Pby/1PVvNrNvMuvv6+mat/mvWr2BkPE/3q0dn7ZgiIgtN3YLEzJYC3wB+x937z7RpiTY/Q/upje53u/tGd9/Y0dFRebGnsfn85WTTKR59uXfWjikistDUJUjMLEMSIl9x978LzQfDcBXhufDXuQdYU7R7F7A/tHeVaJ8zTdmITect49GXZ6+XIyKy0NTjrC0DPg/sdPdPF330EHBzeH0z8GBR+xYzi83sPJJJ9SfC8NeAmW0Ox7ypaJ85c836Fbx88AQHjg/P9VeLiMwL9eiRXA38CvA+M/txePwc8Ang/Wa2C3h/eI+7Pw88ALwAfAe4zd0Ls9u3AveQTMD/G/DtOf1JgPesT6ZyHlOvREQWqWiuv9Ddf0Dp+Q2Aa0+zzzZgW4n2buDS2auucutXLeWslgYefbmPD//EOfUsRUSkLnRl+wyZGdesX8EPdh0ipwUcRWQRUpDMgvesX0n/SI5neo7VuxQRkTmnIJkF775gBSmDR1/SPImILD4KklnQ2pTh8jVtPLrrUL1LERGZcwqSWfKe9St5tucYRwbH6l2KiMicUpDMkvdc2IE7/PMuDW+JyOKiIJklb+9spa0pw2Mva3hLRBYXBcksSaeMn1rXwaMv95HPl1zyS0TkLUlBMoves76DQydGeWqvVgMWkcVDQTKL3r9hFataYv7bN55leEz3KBGRxUFBMotaGzN8+t9dzr/1DbLtWy/UuxwRkTmhIJllV1+wgq3XnM+X/99e/vGFg/UuR0Sk5hQkNfD7H1jPhtUt/OE3nqV3YKTe5YiI1JSCpAbiKM1nt1zO4GiOP/jbZ3UWl4i8pSlIamTdqmb+6Ocv5rGX+7j3X1+tdzkiIjWjIKmhj24+l2svWsm2b+3UfImIvGUpSGrIzPjsR67g0rNb+M2vPsW/7tZV7yLy1qMgqbGlccS9v7qJtcub+LUvdvO0LlYUkbcYBckcaF+S5Uu3XMWKpTH/8a9/xItv9Ne7JBGRWaMgmSOrWhr4yq9dRUMmxUfveYLnXj9e75JERGaFgmQOrVnWxJdvuQpwfuEvfsDv/c2P2XdkqN5liYjMiLkvrmscNm7c6N3d3XWt4fjQOJ97dDf3/suruMOvvOtc/vN73kY6ZRwfHuf48DjHhsZY2dzAxaubMbO61isiYmZPuvvGkp8pSOrnwPFhPvPwLv72yX2c7prFFUtjrlm3gmvWd3D1BStYsTSrYBGROacgKTKfgqRg18EBvvfCQZqyaVobM7Q2ZmhpzPDa4SEee7mPH+w+NHkLXzNozKRpzKRpyKTJpI3xCSeXzyfPE3nWrWrmfRet5H0XreSis9SjEZGZU5AUmY9B8mbyeee5/cd5Ys8R+ofHGR6fYGhsguHxCXITTiadIpM2MukUZvD03mPsCJP5Z7c28O51K1jV0kBrY4a2pixtjRlWNMd0tTeyfIl6OCLy5s4UJNFcFyOVS6WMy7rauKyrrex9evtHeOSlXr7/Yi//uLOXo0NjlPo3Q0MmRWdbI2e3NZJ3Z3B0gqGxHENjE4zl8mTSKaK0EaWSoDpnWRPvPLedd57TzmVdrTRk0mXXlM87g2M5TozmSKeMlc0NZe8rIvOXeiSLRD7vDIzkkon84TF6+0fpOTrE68eG6Tk6zIHjI0QpozGbZkk2oilOk02nyOWd8Yk8uQlnNJdnd+8Arx5OzjSLUsYlZ7dwWVcbb+9q5bKuVi7oWIqZsfNAP0++dpTu147yzL5jHBkc48RobkpNF69u4f0bVvGBDau45OyWyZ7RRN45PDjKkcExGqI0zQ0RSxsi4qj80BKR2aWhrSKLNUhm06ETozy99xhP7T3KU68d5fn9/ZMh0ZBJkTZjMNwhclVLzJXntrO6tZElcURznIRC//A423f20v3aEfKeDMF1tDTQ2z9C78AoEyXOPshGKZrjiIZMmqZsmsZsMk8URynSKSNKpYhSRjZK0d6UDOMtW5KlrSkDwLGhcY4NjXN0aIyBkRyN2RQtDcl8VEtDhihlHB0a48jQGMcGk+2WLcnyto6lvG3lEi7oaKazvZF06tShwKGxHI+93Md3nnuDx3YdIo5SrGppYFVLzFktDaxqbeCslvBoTR5NWQ0IyMKhICmiIJl9+byz5/AgO3qO80zPMXITzpXntnPlue10tTeecQ7m8IlRtr/Yy/adBxkam2BV+GO7qiVm2ZKY0dwEAyPJcFj/yDiDo8mw20iYJxoamyA3kSeXd3LhpIOR8TzHhsboH8mV/M7mOKK5IWIkl6d/eJzctNDKplO0NWVoa8pw+MQYh8OJDoXPVk4Lh31HhnhsVx8j43namzL89IUrMTN6B0Z44/gIB/tHStaSSVty4kQ2TVM2YmkcsW7lUjac3cIlZ7eyYXULzQ0RhwZHeeP4CAfCsYbGJhgdzzOam2A0l8eAc5Y3ce7yJaxd3kRnWyNROrlEbCLvjOXyjE3kacykyUZTLx3L551DJ0Y5cHyEN/qTXmkhWFsaI5bEEQYU/4ZSZsmcXCpFqkSoFrg7PUeHeXrfMXb0HCNlxurWBla3NXJ2ayMrW+LJGifyjjsMj09MngLfPzzOwMg4DZk0LY0ZmhsiWhoyLFuSZXVrw+TPWOp7B0ZzNGbSZE6zTbVGxifoOTrM0jhi+dLsrB9/toyMT3BiNMfSOCKOUrMyD6ogKaIgWTxyE3mODyc9C4C2piytjZkp/+d3d4bHk7Aay+VZtiRLUzY95f94RwfHeOXQCf6td5BXDg1ysP9kQBw4PkJrY4brLlnFdZeexaa1y0r+gRsem+CN/hEOHB8O+4/SPzLO8NhE8hif4NjwOC8e6Kd3YHRyvyhlpwRdQSZtxFF6MjyL94mjFKO5fMmQXNoQsSROk8/Dwf6R0x6/HOmUkU2naGmMaG9Ken/LlmQZHc/zTM8xDp1IfvdxlMIdxibyb3LE8mTSxpr2JtauWMK5y5sYn8jTc3Q4PIYmfx8NmRRL4wwtDRHNhTMiGyJawutVzTGd7Un4drY30tIQ0T+S4/CJUQ6dGOPQiVH2HBrkxTcGePFAP68cGpzSW25ryrBiacyypmwyLBynacwkv984SoUTYVJkoxSNmTSrWxvobG+ks62RZac50cXdOTY0PjnsPDAyTnMI9paGpG4zGJ9Ihp3HcnkGRnLsPNDPc/uP8/zr/ezuOzFZZ5QylsTJP1T+63UXcuMVnVX9zhUkRRQkMpvcfdbPeusbGOWFA/08v/84g6O5MBzWyOrWBla2xDTHGbJhOK9QQ9+JUV49NMSrhwd57fAgI+N54ihFHKWJM8mQX/Kv1AkGR5MengFntTYkvYTWRla1NJB3p39knP7hkz3A6fLuk3/ECn/IksBOLqQ9MjhGypITRC4/p40r1rRx4VnNpM04PDjGgePD7D82wqETo5hB2oxUykibEWdSk6fAtzZmWBpHjObyJ2saHufQiVFePTzEa4cH2XNokNcODxFnUnS1N9LV1kRXe/KzjIxPMDCaY2BknP6RXOjhJM/9I0mvZ3xi6t+/dMpKDqt2tjVy8epmLjqrhfM7ljA0NsGhE6McDmFzdGiM4bEJBsM/DAbHkn+YJL+j0n9jGzIp2hqzpFNGKgVRKvkHSKHXWY0VS2Pe3tnCpZ2trFgaJye3jOTC/+YT/NKVnfzk21ZUdey3dJCY2fXAZ4E0cI+7f+JM2ytIRASSAD50YozXjw3z+tFhXj82xNGhcZY1ZVnRnGXF0pjlS2K6ljXS0pCZ0feMTeQZGp1Ivmvy+5LexkQeJvJ5JjzZtqM5prOtka72RjrbmmhtzDAwejLcjw+Pg0MmsskeT1M2zYWrmlnZUrszId+yp/+aWRr4S+D9QA/wIzN7yN1fqG9lIjLfmRkdzTEdzTGXr2mr6ffEUZo4StO+JMulna01+656mZ8zReXbBOx291fcfQy4H7ihzjWJiCwqCz1IOoF9Re97QtsUZrbVzLrNrLuvr2/OihMRWQwWepCUmuU8ZdLH3e92943uvrGjo2MOyhIRWTwWepD0AGuK3ncB++tUi4jIorTQg+RHwDozO8/MssAW4KE61yQisqgs6LO23D1nZr8FfJfk9N8vuPvzdS5LRGRRWdBBAuDu3wK+Ve86REQWq4U+tCUiInW24K9sr5SZ9QGvVbn7CuDQLJYzVxZq3bBwa1fdc0t119657l7ytNdFFyQzYWbdp1siYD5bqHXDwq1ddc8t1V1fGtoSEZEZUZCIiMiMKEgqc3e9C6jSQq0bFm7tqntuqe460hyJiIjMiHokIiIyIwoSERGZEQVJmczsejN7ycx2m9nt9a7ndMzsC2bWa2bPFbUtM7OHzWxXeG6vZ42lmNkaM3vEzHaa2fNm9rHQPq9rN7MGM3vCzJ4Jdf9xaJ/XdReYWdrMnjazfwjv533dZvaqme0wsx+bWXdoWwh1t5nZ183sxfDf+bsWQt3lUJCUoehOjD8LbAA+YmYb6lvVad0LXD+t7XZgu7uvA7aH9/NNDvh9d78Y2AzcFn7H8732UeB97v4O4HLgejPbzPyvu+BjwM6i9wul7p9298uLrsFYCHV/FviOu18EvIPk974Q6n5z7q7HmzyAdwHfLXp/B3BHves6Q71rgeeK3r8ErA6vVwMv1bvGMn6GB0luobxgageagKeAqxZC3SS3XdgOvA/4h4Xy3wrwKrBiWtu8rhtoAfYQTnBaKHWX+1CPpDxl3YlxHlvl7gcAwvPKOtdzRma2FrgCeJwFUHsYHvox0As87O4Lom7gM8AfAvmitoVQtwPfM7MnzWxraJvvdZ8P9AF/HYYS7zGzJcz/usuiIClPWXdilJkzs6XAN4Dfcff+etdTDnefcPfLSf6Fv8nMLq1zSW/KzD4I9Lr7k/WupQpXu/s7SYaabzOza+pdUBki4J3AXe5+BTDIQh3GKkFBUp6FfifGg2a2GiA899a5npLMLEMSIl9x978LzQuidgB3Pwb8E8kc1Xyv+2rgF83sVeB+4H1m9mXmf924+/7w3Av8H2AT87/uHqAn9FYBvk4SLPO97rIoSMqz0O/E+BBwc3h9M8n8w7xiZgZ8Htjp7p8u+mhe125mHWbWFl43Aj8DvMg8r9vd73D3LndfS/Lf8/fd/aPM87rNbImZNRdeAx8AnmOe1+3ubwD7zOzC0HQt8ALzvO5y6cr2MpnZz5GMKRfuxLitvhWVZmZfA95Lsjz1QeDjwN8DDwDnAHuBD7n7kTqVWJKZvRv4Z2AHJ8fs/zvJPMm8rd3MLgPuI/nvIgU84O7/y8yWM4/rLmZm7wX+wN0/ON/rNrPzSXohkAwXfdXdt833ugHM7HLgHiALvAL8KuG/GeZx3eVQkIiIyIxoaEtERGZEQSIiIjOiIBERkRlRkIiIyIwoSEREZEYUJCJlMrN/Dc9rzezf1/B7PnOmq7XNrMnMvhlWkX3ezD5R9FlsZn8TVql+PCw3U7je5Tu1qlkWNwWJSJnc/SfDy7VARUESVpAuZ7tlwGZ3f+xNNv2UJ6vIXgFcbWY/G9pvAY66+wXAnwOfDLX3AQfM7OpK6hYph4JEpExmdiK8/ATwU+F+GL8bFm38MzP7kZk9a2a/EbZ/ryX3WPkqsCNclf3NcO+S58zswyW+5peB74T9Wy25B86F4f3XzOzX3X3I3R8BcPcxkhWHu8L+N5BcIAnJMhzXhlUDILkw9T/M5u9EBJIrQ0WkMrcTrgQHCCvQHnf3nzCzGPgXM/te2HYTcKm77zGzXwL2u/vPh/1aSxz7apIAwN2Pm9lvAfea2WeBdnf/q+KNw/Isv0ByrwsoWqna3XNmdhxYDhwCuoE/mZXfgEgR9UhEZu4DwE1hKfnHSf5wrwufPeHue8LrHcDPmNknzeyn3P14iWOtJlluHAB3fzjs95fArxVvaGYR8DXgTnd/pdBc4piF5St6gbMr/NlE3pSCRGTmDPhtT+7Yd7m7n+fuhR7JYGEjd38ZuJIkGP7UzP5niWMNAw2TBzZLAReH9mXTtr0b2OXunylqm1ypOgRNK1BYu6khHEdkVilIRCo3ADQXvf8ucGtYBh8zWx9Wpp3CzM4Ghtz9y8CnSJYRn24ncEHR+98NbR8BvlD0HX9CEhK/M23/4tVkf5lkVd9Cj2Q9yUq5IrNKcyQilXsWyJnZM8C9JPMTa4GnwsR2H3Bjif3eDvyZmeWBceDWEtt8E/gN4B4zW08ynLXJ3QfM7DHgj8zsr4D/QbJc/VNhLv0v3P0ekqX4v2Rmu0l6IluKjv3T4fgis0qr/4rMM2b2A+CD4UZZs3ncx4Ab3P3obB5XREEiMs+Y2VXAsLs/O4vH7CC5Re3fz9YxRQoUJCIiMiOabBcRkRlRkIiIyIwoSEREZEYUJCIiMiMKEhERmZH/D7vmAhh9hsAOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = np.arange(len(ppl_list))\n",
    "plt.plot(p, ppl_list, label='train')\n",
    "plt.xlabel('iters (x' + str(eval_interval) + ')')\n",
    "plt.ylabel('ppl')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
